<p align="center">
<img src="logo.png" align="center" width="100%" style="margin: 0 auto">
</p>

---

## Overview

This repository contains files for automatically choose tickers with maximized expected rate of return. To make sure the validity of every parts behind the ticker selecting decision, this repository provide a back test pipeline to review the performace of models over certain periods. Furthermore, it also provides different kinds of feature selection and hyperparameter tuning methods for users to compare the corresponding performance with the basic result. In the future, this pipeline will also involve different model interpretation strategies to enhance the confidence of selecting tickers recommended by the model.

## Introduction

The whole project is called empirical asset pricing with machine leaning, which will build a stable and robust prediction pipeline for portfolio investment. This project will include 
:

 - Highly robust feature selection and leak detection
 - Accurate and various hyper-parameter optimization in high-dimensional space
 - State-of-the-art predictive models for regression task about rate of return
 - Automatic results evaluation with metrics reports and plots
 - Predictions with interpretations

## Structure of Repository folders/files

 - **`additions`**: Store additional materials for the whole project
 - **`config`**: All configuration json files are stored here
 - **`data`**: This is the warehouse to store all required or automatically generated datasets for the experiments and the whole project
 - **`papers`**: All reference papers shoule be uploaded into this file for future usage and referring
 - **`result`**: An automatically generated folder used to keep all results that generated by the code
 - **`tools`**: It contains all codes with well-wrapped functions and methods that will be frequently used in the future

## AWS setting 
 - Register AWS account and genreate new access secret key
 - Install AWS CLI 
    - command: `pip install awscli`
      - for windows : `https://awscli.amazonaws.com/AWSCLIV2.msi`
    - command: `aws configure`
    - AWS Access Key ID: *******(due to AWS security rule, please use your own key_id)
    - AWS Secret Access Key: *******(due to AWS security rule, please use your own key_id))
    - Default region name: ap-southeast-1
    - Default output format: json
 - Go to aws folder
    - command: `cd .aws`
    - command: `cat credentials`
- Install boto3
    - command: `pip install boto3`
- check `status.csv`
    - search `S3` in AWS website and find `mas-backtest` bucket
- AWS EC2 (AWS Linux instance t2)
   - activae instance 
   - find `id_rsa`
   - connect to instance
      - perform a quick update on the instance `sudo yum update -y`
      - install git in the instance `sudo yum install git -y`
         - `git version`
         - `git clone ` + github.com (the source file url)
- Install Anaconda3 (https://medium.com/@GalarnykMichael/aws-ec2-part-3-installing-anaconda-on-ec2-linux-ubuntu-dbef0835818a)
   - `wget https://repo.anaconda.com/archive/Anaconda3-5.3.1-Linux-x86_64.sh`, select latest version
   - `bash ` + the anaconda file downloaded (enter yes, enter to accept terms and finish installation)
   - `vi .bashrc` , then copy `export PATH=/home/ec2-user/anaconda/bin:$PATH` into bash file
   - `source .bashrc`

# two options: 
1) cloud (AWS)
2) local (ex: three computers, choose one master node )

## virutal environmnet
- Set up virtual environment
   - create virtual environment `backtest_env` with all necessary dependencies
      - command: `conda env create -f env.yml`
   - activate 'backtest_env'
      - command: `conda activate backtest_env`
   - check location of 'mas_env'
      - command: `conda env list`

## Dependencies

The basic requirements are listed below:

```
boruta==0.3
yahoo_fin==0.8.9.1
lightgbm==3.3.1
python-dateutil==2.8.1
pandas==1.1.3
numpy==1.19.2
scikit-learn
tensorflow==2.7.0
keras==2.7.0
tqdm==4.50.2
optuna==2.10.0
```

More Details about all the packages dependencies for my Mac laptop are recorded in `requirements.txt`. Check it if you have any unexpected version issue.

## How to Run

Before running the code, make sure all datasets required in the code are placed in the `data` folder. The required datasets are:
 - features data from gkx (automatically generated in the future)
 - SPY daily price (auto)
 - SP500 daily price (auto)
 - sp500_list

The `sp500_list.csv` contains the primary key of the feature data, which shoule be confirmed in the future. Currently, it is just fixed.

The 2 daily price data file can be generated by running test code in the `tools/yh_data.py`

```
df = download_sp500("1999-12-01", "2021-12-31")
df.to_csv('./sp500_daily_prc.csv', index=False)
df = download_spy("1999-12-01", "2021-12-31")
df.to_csv('./spy_daily_prc.csv', index=False)
```

The final code will be in the `back_test.py`.

After modifying the information in the correspoding configuration file in `config`, run:

```
python back_test_new.py
```
After completion, all expected results will wait for you in the `result` folder.

## Configuration Settings

Take the configuration of back test as an example:

```
{    
    "kfold": 4, # No. of folds for validation
    "train_period": 5, # No. of years for the time period of train set in validation
    "test_period": [1], # list of No. of months for test prediction
    "topk": 10, # No. of tickers to select as protfolio
    "money": 100000, # Initial fund amount for investment
    "train_end_ym": "201512", # traing end date with format %Y%m
    "tune_sampler": "tpe", # method for HPO
    "train_valid_period": [15], # list of No. of years for time period of training validation set
    "tune_trials": 15, # No. of trails for HPO
    "md": "lgb", # model selected to do experiment
    "fs": "" # method of feature selection
}
```


## Outputs

The outputs shoule all be placed in `result` folder.

Considering different combinations of `train_valid_period` and `test_period`, in the `result` folder there will be different folders with name rules `A_B`, a spreadsheet to record the corresponding metrics for these combinations, like:

| **train_valid_period** | **test_period** | **Calmar Ratio** | **annual return** | **max draw down** |
|------------------------|-----------------|-------------------|-------------------| ---|
| 11                      |      1           |       0.419961679            |          24.11         |-57.41 |
		
and a heatmap to help you find the best combination, like:

<p align="center">
<img src="result/heatmap_summary.png" align="center" width="100%" style="margin: 0 auto">
</p>

In each folder, it contains a plot like:

<p align="center">
<img src="result/kpi.png" align="center" width="100%" style="margin: 0 auto">
</p>

and 2 csv files to trace the daily portfolio value trend and the ticker selection strategies for each part of the back test.

## Existing Issues

1. Data source problem: current `ret` is from yahoo-finance with (ticker, date with %Y%m%d) as primary key, but the GKX features use (ticker, permno, date with %Y%m) instead. So, there will be some data dropped during the merge operation since some ticker may have different permno at different periods.

2. there are some permno overlapping for some tickers in GKX feature data. Commonly, although some ticker may have different permnos in different periods, but these periods should not overlap since for a specific day, one ticker should only map one permno.

3. After doing feature selection, the predictions should have performed worse than those with all features, but current results shows less features can get better results.

4. ~~The intuive expectation of the predictions is that longest train_valid_period and shortest test_period could get the best prediction and thus achive the highest return from the portfolio. But current heatmap shows that this intuition is not that correct. So we still need to spend time on whether the code is wrong or such phenomenon is just true. One hint is that when test_period > 1, after selecting the top-k tickers, you can verify whether the portfolio changing trend could keep pace with each ticker's trend according to yahoo-finance.~~

## TODO List

- [ ] confirm one most reliable data source for rate of return calculating. Options: CRSP, yahoo-finance...
- [ ] fix the duplication problem and try best to preserve all the GKX features after merging
- [ ] Try to split current back test workflow to parallel calculation
- [ ] add model interpretation part
- [ ] make sure all parameters that should be set by users in the configuration file (current json file is not enough)
- [ ] finish code for future experiment when going live
- [ ] find a better way to decide which is a better combination of the [`train_valid_period`, `test_period`, `topk`] since these hyperparameters will directly affect the definition of the task
- [] train_period, topk should also be lists in configuration json file.