import os
import io
import boto3
import json
import optuna
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
#from lightgbm import LGBMRegressor
from sklearn.linear_model import LinearRegression
from dateutil.relativedelta import relativedelta
from itertools import product
import warnings
warnings.filterwarnings("ignore")

from tools.metrics import oos_rsquare
from tools.model_selection import rolling_valid_split
from tools.feature_selector import feature_selection
sns.set()

args = json.load(open('./config/back_test.json', 'r'))
if not os.path.exists('./result/'):
    os.makedirs('./result/')

y_col_prefix = args['y_col_prefix']
pred_col = 'pred_ret'
dummy_cols = args['primary_key']
kfold = args['kfold']
train_end_ym = args['first_train_end_ym']
tune_sampler = args['tune_sampler']
md = args['md']

fs_tool = args['fs']
if tune_sampler == 'tpe':
    sampler = optuna.samplers.TPESampler(seed=2020)
elif tune_sampler == 'random':
    sampler = optuna.samplers.RandomSampler(seed=2020)
elif tune_sampler == 'nsga':
    sampler = optuna.samplers.NSGAIISampler(seed=2020)
elif tune_sampler == 'cma':
    sampler = optuna.samplers.CmaEsSampler(seed=2020)
else:
    raise ValueError('invalid sampler value')

# read from AWS s3 
def read_file(filename, key_id, access_key):
    s3 = boto3.resource('s3', aws_access_key_id= key_id, aws_secret_access_key=access_key)
    obj = s3.Object('backtest-11-papers', filename)
    data=obj.get()['Body'].read()
    df = pd.read_csv(io.BytesIO(data), header=0, delimiter=",", low_memory=False, index_col = 0)
    return df

# ask the user for key_id and access_key
# since if upload to github, account will suspend
key_id = input('aws_access_key_id: ')
access_key = input('aws_secret_access_key: ')

# this data can be automatically generated by yh_data.py in tools
#daily_prc = pd.read_csv('./data/sp500_daily_prc.csv')
daily_prc = read_file('sp500_daily_prc.csv', key_id, access_key)
daily_prc = daily_prc.reset_index()
daily_prc['date'] = pd.to_datetime(daily_prc['date'])
daily_prc['year'] = daily_prc['date'].dt.year
daily_prc['month'] = daily_prc['date'].dt.month
daily_prc = daily_prc.sort_values(['ticker', 'date']).reset_index(drop=True)
# legal ticker at certain month should be sold for a specific period (fixed length)
counting_max =  daily_prc.groupby(['ticker', 'year', 'month'])['date'].count().reset_index()
# counting_max will be used to validate ticker when selecting top-k tickers
counting_max = counting_max.groupby(['year', 'month'])['date'].max()


df = read_file('paper9_final.csv', key_id, access_key)
df = df.reset_index()
#df = pd.read_csv('./data/paper9_final.csv')
# processing the raw data
df['date'] = pd.to_datetime(df['date'])
# rename the `date` in origin data to `trade_date`
df['trade_date'] = df['date'].values
y_cols = [f'fut_ret{col}' for col in args['test_period']]
dummy_cols = dummy_cols + ['trade_date']
feat_cols = [col for col in df.columns if col not in (dummy_cols + y_cols)]
# new `date` will be used to trace the back test process
df['date'] = df['date'] + pd.tseries.offsets.MonthEnd(n=0) - pd.tseries.offsets.MonthBegin(n=1)

# TODO fillna [Feature Engineer should do]
df[feat_cols] = df[feat_cols].fillna(0)

train_end_date = pd.to_datetime(train_end_ym, format='%Y%m')
money = args['money']
pf_daily_trend = pd.DataFrame()
# record all the important results in a csv file
f = open(f'./result/final_summary.csv', 'w', encoding='utf-8')
f.write('start date,end date,train_valid_period(years),test_period(months),train_period(years),topk,feature_selection,Annual Return,MDD,Calmar Ratio\n')


while train_end_date < df['date'].max():
    print(f'[combo selection]End date of training is: {train_end_date}')
    combo_cnt = 0
    # choose combination of train_valid_date, test_period:
    calmar_ratio_res = pd.DataFrame({
        'train_valid_period':[], 'test_period': [],
        'train_period': [], 'topk': [], 'fs': [], 'cr': []
    })
    ar_res = pd.DataFrame({
        'train_valid_period':[],'test_period': [],
        'train_period': [], 'topk': [], 'fs': [], 'ar': []
    })
    mdd_res = pd.DataFrame({
        'train_valid_period':[], 'test_period': [],
        'train_period': [], 'topk': [], 'fs': [], 'mdd': []
    })

    pf_daily_res = {}
    fund_res = {}

    init_fund = money

    for combo in product(args['train_valid_period'], args['test_period'], args['train_period'], args['topk'], args['fs']):
        print('current combination:', combo)
        train_valid_period = combo[0]
        test_period = combo[1]
        train_period = combo[2]
        topk = combo[3]
        fs_tool = combo[4]
        valid_period = test_period
        # change year to month
        train_valid_period *= 12
        train_period *= 12

        y_col = f'{y_col_prefix}{test_period}'
        data = df[dummy_cols + feat_cols + [y_col]].copy()
        data = data.dropna()
        actual_train_end_date = train_end_date - relativedelta(months=test_period - 1)

        train_start_date = train_end_date - relativedelta(months=train_valid_period)
        predict_end_date = train_end_date + relativedelta(months=test_period)
        predict_dates = pd.date_range(
            start=train_end_date + relativedelta(months=1), end=min(predict_end_date, df['date'].max()), freq='MS')

        valid_date_sets = rolling_valid_split(kfold, train_period, train_start_date, actual_train_end_date, valid_period)
        train_data = data.query(f'"{train_start_date}" < date <= "{actual_train_end_date}"')
        X_train = train_data[feat_cols].values
        y_train = train_data[y_col].values

        # implement feature selection, 'mi', 'boruta', 'ae', ''
        _, select_ids = feature_selection(X_train, y_train, method=fs_tool, k=25)
        if sum(select_ids) == 0:
            select_ids = [True for _ in feat_cols] # TODO
        '''
        def objective(trial):
            param = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 500),   
                'num_leaves': trial.suggest_int('num_leaves', 10, 512),
                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 80),
                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.0, 1.0), # subsample
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # eta
                'lambda_l1': trial.suggest_float('lambda_l1', 0.01, 1),  # reg_alpha
                'lambda_l2': trial.suggest_float('lambda_l2', 0.01, 1), # reg_lambda
            }
            kpis = []
            for valid_train_start_date, valid_train_end_date, valid_end_date in valid_date_sets: 
                fold_train_data = data.query(f'"{valid_train_start_date}" < date <= "{valid_train_end_date}"')
                fold_valid_data = data.query(f'"{valid_train_end_date}" < date <= "{valid_end_date}"')
                train_x = fold_train_data[feat_cols].values[:, select_ids]
                train_y = fold_train_data[y_col].values
                val_x = fold_valid_data[feat_cols].values[:, select_ids]
                val_y = fold_valid_data[y_col].values
                model = LGBMRegressor(seed=42, **param)
                model.fit(train_x, train_y)
                y_pred = model.predict(val_x)
                kpi = oos_rsquare(val_y, y_pred)
                kpis.append(kpi)
            return np.mean(kpis)
        
        study = optuna.create_study(
            direction="maximize", 
            sampler=sampler, 
            study_name=f'train_end_date_{train_end_date}'
        )
        study.optimize(objective, n_trials=args['tune_trials'])
        # use best hyperparameters to train this part of back test
        param = study.best_params
        model = LGBMRegressor(seed=42, **param)
        model.fit(X_train[:, select_ids], y_train)
        '''
        model = LinearRegression()
        model.fit(X_train[:, select_ids], y_train)
        # record investment changes for next `test_period` months
        # run prediction in the first predict month and rebalance the investment after `test_period` month
        # print('--------\n', predict_dates, '\n--------\n')
        predict_date = predict_dates[0]
        test_data = data.query(f'date == "{predict_date}"')
        X_test = test_data[feat_cols].values[:, select_ids]
        y_test = test_data[y_col].values

        outputs = test_data[dummy_cols + [y_col]].copy()
        outputs[pred_col] = model.predict(X_test)

        # descending sort values to select topk-stocks
        outputs = outputs.sort_values(by=[pred_col], ascending=False)
        # find out the legal ticker will have how many days recording during `test_period` months
        ideal_ser_num = sum([counting_max[(pdt.year, pdt.month)] for pdt in predict_dates])
        # equally separate investment to `topk` folds
        allocate_fund = init_fund / topk
        # store the portfolio value changing records during next `test_period` months
        ticker_recs_this_month = []
        # store the expected portfolio value for next rebalance strategy
        new_money = 0.
        idx, cnt = 0, 0
        tickers_tmp_info = []
        while cnt < topk:
            # select the ticker name with rank number `idx`
            ticker_name = outputs.iloc[idx, :]['ticker']
            # select the daily changing prices of this ticker
            et = predict_dates[-1] + pd.tseries.offsets.MonthEnd(n=1)
            ticker_ts = daily_prc.query(
                f'"{str(predict_dates[0].date())}" <= date <= "{str(et.date())}" and ticker == "{ticker_name}"')
            if len(ticker_ts) != ideal_ser_num:
                # this ticker is illegal, just skip and find next.
                idx += 1
                continue
            else:
                # legal ticker, just sort by datetime again for insurance
                ticker_ts = ticker_ts.sort_values(by=['date']).reset_index(drop=True) 
                # the first price in ticker_ts will be the purchase price of this ticker
                purchase_price = ticker_ts.head(1)['adjclose'].values[0]
                purchase_amount = allocate_fund / purchase_price
                # record daily price for this ticker, this list will store value changes for each top-k ticker
                # it will be summed in next code to represent the portfolio changes
                ticker_recs_this_month.append(purchase_amount * ticker_ts['adjclose'].values)
                # the last price in ticker_ts will be the selling price of this ticker
                sell_price = ticker_ts.tail(1)['adjclose'].values[0]
                sell_return = sell_price * purchase_amount
                # add the return money of this ticker after `test_period` months
                new_money += sell_return
                tickers_tmp_info.append(ticker_name)
                cnt += 1
                idx += 1
        selected_pf_daily = pd.DataFrame({
            'date': ticker_ts['date'].values, 
            'val': np.sum(ticker_recs_this_month, axis=0)}) 
        t1, t2 = selected_pf_daily['date'].min(), selected_pf_daily['date'].max()
        y_num = (t2 - t1).days / 365
        ar = round(np.power(selected_pf_daily['val'].iloc[-1] / selected_pf_daily['val'].iloc[0], 1 / y_num) - 1, 4)
        selected_pf_daily['cummax'] = selected_pf_daily['val'].cummax()
        selected_pf_daily['drawdown'] = (selected_pf_daily['val'] - selected_pf_daily['cummax']) / selected_pf_daily['cummax']
        mdd = round(selected_pf_daily['drawdown'].min(), 4)
        cr = ar / abs(mdd)

        calmar_ratio_res.loc[combo_cnt, :] = [train_valid_period//12, test_period, train_period//12, topk, fs_tool, cr]
        ar_res.loc[combo_cnt, :] = [train_valid_period//12, test_period, train_period//12, topk, fs_tool, ar]
        mdd_res.loc[combo_cnt, :] = [train_valid_period//12, test_period, train_period//12, topk, fs_tool, mdd]
        

        line = f'{str(t1.date())},{str(t2.date())},{train_valid_period//12},{test_period},{train_period//12},{topk},{fs_tool},{ar},{mdd},{cr}\n'
        f.write(line)
        f.flush()

        pf_daily_res[combo_cnt] = selected_pf_daily[['date', 'val']].copy()
        fund_res[combo_cnt] = new_money
        combo_cnt += 1
    
    best_combo = calmar_ratio_res.query(f'cr == {calmar_ratio_res.cr.max()}').index[0]
    best_test_perid = calmar_ratio_res.loc[best_combo, 'test_period']
    attach_pf_daily = pf_daily_res[best_combo]
    money = fund_res[best_combo]
    pf_daily_trend = pd.concat([pf_daily_trend, attach_pf_daily], ignore_index=True)
    # # draw combo-CR hearmap
    # fig, ax = plt.subplots(1, 3, figsize=(20, 5))
    # sns.heatmap(
    #     ar_res.pivot("train_valid_period", "test_period", "ar"), 
    #     ax=ax[0], cbar_kws={'format': '%.0f%%'}, 
    #     cmap=sns.color_palette("Blues", as_cmap=True))
    # ax[0].set_title(f'Portfolio Annual Return', fontsize=16, fontweight='bold', loc='left')
    # sns.heatmap(
    #     mdd_res.pivot("train_valid_period", "test_period", "mdd"), 
    #     ax=ax[1], cbar_kws={'format': '%.0f%%'}, 
    #     cmap=sns.color_palette("ch:start=.2,rot=-.3", as_cmap=True))
    # ax[1].set_title(f'Portfolio Max DrawDown', fontsize=16, fontweight='bold', loc='left')
    # sns.heatmap(
    #     calmar_ratio_res.pivot("train_valid_period", "test_period", "cr"), ax=ax[2])
    # ax[2].set_title(f'Portfolio Calmar Ratio', fontsize=16, fontweight='bold', loc='left')
    # for i in range(3):
    #     ax[i].set_ylabel('train_valid_period', fontweight='bold', fontsize=14)
    #     ax[i].set_xlabel('test_period', fontweight='bold', fontsize=14)

    # sdt, edt = attach_pf_daily['date'].min(), attach_pf_daily['date'].max()
    # ax[0].text(
    #     x=0., y=1.13, 
    #     s=f'{str(sdt.date())} ~ {str(edt.date())}', 
    #     fontsize=18, fontweight='bold', ha='left', va='top', transform=ax[0].transAxes)

    # plt.tight_layout()
    # plt.savefig(f'./result/heatmap_summary_from_{sdt.year}{sdt.month:02d}_to_{edt.year}{edt.month:02d}.png', format='png')
    # plt.close()

    # to next back test part
    train_end_date = train_end_date + relativedelta(months=best_test_perid)
# finish recording, close the csv file
f.close()

# output 3 kpi plots
t1, t2 = pf_daily_trend['date'].min(), pf_daily_trend['date'].max()
y_num = (t2 - t1).days /365

spy_df = pd.read_csv('./data/spy_daily_prc.csv')
spy_df['date'] = pd.to_datetime(spy_df['date'])
spy_daily = spy_df.query(
    f'"{pf_daily_trend.date.min()}" <= date <= "{pf_daily_trend.date.max()}"')[['date', 'ticker', 'adjclose']]
spy_daily['year'] = spy_daily.date.dt.year
spy_daily['month'] = spy_daily.date.dt.month
spy_daily = spy_daily.sort_values(by=['date']).reset_index(drop=True)  
spy_daily['value'] = spy_daily['adjclose']

pf_daily_trend['date'] = pd.to_datetime(pf_daily_trend['date'])
pf_daily_trend['month'] = pf_daily_trend['date'].dt.month
pf_daily_trend['year'] = pf_daily_trend['date'].dt.year
pf_daily_trend.sort_values(['date'], inplace=True)
pf_daily_trend['cummax'] = pf_daily_trend['val'].cummax()
pf_daily_trend['drawdown'] = (pf_daily_trend['val'] - pf_daily_trend['cummax']) / pf_daily_trend['cummax']
ar = round(np.power(pf_daily_trend['val'].iloc[-1] / pf_daily_trend['val'].iloc[0], 1 / y_num) - 1, 4) * 100

yearly_return = pf_daily_trend.groupby(['year']).apply(
            lambda x: (x['val'].iloc[-1] - x['val'].iloc[0]) / x['val'].iloc[0])
max_drawdown = round(pf_daily_trend.drawdown.min(), 4) * 100 

# make predit_dates for future plots
tmp = pf_daily_trend[['year', 'month']].drop_duplicates()
all_predict_dates = tmp['year'] * 100 + tmp['month']
all_predict_dates = all_predict_dates.astype(str).agg(lambda x: pd.to_datetime(x, format='%Y%m')).values

# calculate SPY related KPI
spy_daily.sort_values(['date'], inplace=True)
spy_money = args['money']
spy_buy_price = spy_daily.head(1)['adjclose'][0]
spy_amt = spy_money / spy_buy_price
spy_daily['value'] *= spy_amt

spy_daily['cummax'] = spy_daily['value'].cummax()
spy_daily['drawdown'] = (spy_daily['value'] - spy_daily['cummax']) / spy_daily['cummax']
spy_ar = round(np.power(spy_daily['value'].iloc[-1] / spy_daily['value'].iloc[0], 1 / y_num) - 1, 4) * 100
spy_max_drawdown = round(spy_daily.drawdown.min(), 4) * 100 
spy_yearly_return = spy_daily.groupby(['year']).apply(
    lambda x: (x['value'].iloc[-1] - x['value'].iloc[0]) / x['value'].iloc[0])

# Draw plots
fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(20, 15))
sns.set_theme(palette=sns.color_palette("Set1"))

ax[0].plot(np.arange(len(pf_daily_trend['date'])), pf_daily_trend['val'], label='Porfolio')
ax[0].plot(np.arange(len(spy_daily['date'])), spy_daily['value'], label='SPY')
ax[0].axhline(args['money'], ls='--', c='grey', alpha=0.5)

ax[0].set_xlabel('Date', fontweight='bold', fontsize=18)
ax[0].set_ylabel('Portfolio Value', fontweight='bold', fontsize=18)
ax[0].text(x=0, y=1.16, s='Model vs SPY', 
        fontsize=22, weight='bold', ha='left', va='bottom', transform=ax[0].transAxes)
ax[0].text(x=0., y=1.08, 
        s=f'Portfolio: Annual Return = {ar:.2f}%, Max DrawDown = {max_drawdown:.2f}%, Calmar Ratio = {ar/abs(max_drawdown):.2f};', 
        fontsize=15, alpha=0.8, ha='left', va='bottom', transform=ax[0].transAxes)
ax[0].text(
    x=0., y=1.01, 
    s=f'SPY: Annual Return = {spy_ar:.2f}%, Max DrawDown = {spy_max_drawdown:.2f}%, Calmar Ratio = {spy_ar/abs(spy_max_drawdown):.2f}', 
    fontsize=15, alpha=0.8, ha='left', va='bottom', transform=ax[0].transAxes)

y_scaler = np.linspace(min(pf_daily_trend['val'].min(), spy_daily['value'].min()), 
                    pf_daily_trend['val'].max(), 6)
ax[0].set_yticks(y_scaler)
ax[0].set_xticks(np.arange(0, len(pf_daily_trend['date']), 90))
ax[0].set_xticklabels(
    [str(pf_daily_trend['date'].values[idx])[:10] for idx in np.arange(0, len(pf_daily_trend['date']), 90)])
ax[0].legend(fontsize=16)
# ax[0].xaxis.grid(False)

barWidth = 0.2
br1 = np.arange(len(yearly_return))
ax[1].bar(br1 - barWidth / 2, yearly_return, width=barWidth, edgecolor='none', color='red', label='Porfolio (>0)')
ax[1].bar(br1 + barWidth / 2, spy_yearly_return, width=barWidth, edgecolor='none', color='salmon', label='SPY (>0)')
ax[1].bar(
    br1 - barWidth / 2, 
    [t if t <= 0 else 0 for t in yearly_return], 
    width=barWidth, edgecolor='none', color='forestgreen', label='Porfolio (<0)')
ax[1].bar(
    br1 + barWidth / 2, 
    [t if t <= 0 else 0 for t in spy_yearly_return], 
    width=barWidth, edgecolor='none', color='limegreen', label='SPY (<0)')
ax[1].set_xlabel('Year', fontweight='bold', fontsize=18)
ax[1].set_ylabel('Yealy Return', fontweight='bold', fontsize=18)
ax[1].set_xticks(br1)
ax[1].set_xticklabels([idx for idx in yearly_return.index], fontsize=13)
ax[1].set_title('Yearly Return (Model vs SPY)', fontweight='bold', fontsize=22, loc='left')
y_scaler = np.linspace(min(yearly_return.min(), spy_yearly_return.min(), 0), max(yearly_return.max(), spy_yearly_return.max()), 6)
ax[1].axhline(y=0, ls='--', color='gray', alpha=0.5)
ax[1].set_yticks(y_scaler)
ax[1].set_yticklabels([f'{round(v * 100)}%' for v in y_scaler])
ax[1].legend(fontsize=16)

ax[2].plot(
    np.arange(len(pf_daily_trend['date'])), pf_daily_trend['drawdown'], color='teal', label='Porfolio')
ax[2].plot(
    np.arange(len(spy_daily['date'])), spy_daily['drawdown'], color='limegreen', label='SPY')
ax[2].set_xlabel('Date', fontweight='bold', fontsize=18)
ax[2].set_ylabel('Drawdown', fontweight='bold', fontsize=18)
ax[2].set_title(f'Daily Drawdown (Model vs SPY)', fontweight='bold', fontsize=22, loc='left')
ax[2].set_xticks(np.arange(0, len(pf_daily_trend['date']), 90))
ax[2].set_xticklabels(
    [str(pf_daily_trend['date'].values[idx])[:10] for idx in np.arange(0, len(pf_daily_trend['date']), 90)])
y_scaler = np.linspace(
    min(pf_daily_trend['drawdown'].min(), spy_daily['drawdown'].min()), 
    max(0, pf_daily_trend['drawdown'].max(), spy_daily['drawdown'].max()), 6)
ax[2].axhline(y=0, ls='--', color='gray', alpha=0.5)
ax[2].set_yticks(y_scaler)
ax[2].set_yticklabels([f'{round(v * 100)}%' for v in y_scaler])
ax[2].legend(fontsize=16)

plt.tight_layout()
plt.savefig(f'./result/back_test_kpi.png', format='png')
plt.show()
plt.close()


